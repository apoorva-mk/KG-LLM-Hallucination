{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rbanerjee/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rbanerjee/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/rbanerjee/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to /Users/rbanerjee/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rbanerjee/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# import graphvite as gv\n",
    "import dataset\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"simple_wikidata5m.pkl\", \"rb\")\n",
    "model = pickle.load(file)\n",
    "entity2id = model.graph.entity2id\n",
    "relation2id = model.graph.relation2id\n",
    "entity_embeddings = model.solver.entity_embeddings\n",
    "relation_embeddings = model.solver.relation_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias2entity = dataset.wikidata5m.load_alias(\"entity.txt.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2580138\n"
     ]
    }
   ],
   "source": [
    "print(entity2id[alias2entity[\"invented\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who invented machine learning, was it Steve Jobs\n",
      "Steve Jobs PERSON\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm') \n",
    "sentence = \"Who invented machine learning, was it Steve Jobs\"\n",
    "doc = nlp(sentence) \n",
    "print(doc)\n",
    "for ent in doc.ents: \n",
    "    print(ent.text, ent.label_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text: invented machine learning steve jobs\n",
      "Named Entities: (Steve Jobs,)\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Extract named entities\n",
    "    nlp = spacy.load('en_core_web_sm') \n",
    "    named_entities = nlp(text).ents\n",
    "\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    # Part-of-speech tagging\n",
    "    tagged_words = pos_tag(words)\n",
    "\n",
    "    cleaned_text = ' '.join(words).lower()\n",
    "    \n",
    "    return cleaned_text, named_entities\n",
    "\n",
    "# Example usage:\n",
    "text = \"Who invented machine learning, was it Steve Jobs?\"\n",
    "cleaned_text, named_entities = clean_text(text)\n",
    "print(\"Cleaned Text:\", cleaned_text)\n",
    "print(\"Named Entities:\", named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_continuous_word_sets(text, window_size):\n",
    "    words = text.split()\n",
    "    word_sets = []\n",
    "    \n",
    "    for i in range(len(words) - window_size + 1):\n",
    "        word_set = ' '.join(words[i:i + window_size])\n",
    "        word_sets.append(word_set)\n",
    "\n",
    "    return word_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_kg_embeddings(query):\n",
    "    wiki_embeddings = {}\n",
    "    cleaned_text, named_entities = clean_text(query)\n",
    "    for ne in named_entities: \n",
    "        try:\n",
    "            ne = ne.orth_.lower()\n",
    "            wiki_embeddings[ne] = entity_embeddings[entity2id[alias2entity[ne]]]\n",
    "            cleaned_text = cleaned_text.replace(ne, \"\")\n",
    "        except Exception as e:\n",
    "            print(\"KeyError: \", e)\n",
    "    num_of_words = len(word_tokenize(cleaned_text))\n",
    "    for i in range(num_of_words, 0, -1):\n",
    "        word_sets = extract_continuous_word_sets(cleaned_text, i)\n",
    "        for word in word_sets:\n",
    "            try:\n",
    "                wiki_embeddings[word] = entity_embeddings[entity2id[alias2entity[word]]]\n",
    "                cleaned_text = cleaned_text.replace(word, \"\")\n",
    "            except Exception as e:\n",
    "                print(\"KeyError: \", e)\n",
    "\n",
    "    return wiki_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_node_id(query):\n",
    "    node_ids = {}\n",
    "    cleaned_text, named_entities = clean_text(query)\n",
    "    for ne in named_entities: \n",
    "        try:\n",
    "            ne = ne.orth_.lower()\n",
    "            node_ids[ne] = alias2entity[ne]\n",
    "            cleaned_text = cleaned_text.replace(ne, \"\")\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            #print(\"KeyError: \", e)\n",
    "    num_of_words = len(word_tokenize(cleaned_text))\n",
    "    for i in range(num_of_words, 0, -1):\n",
    "        word_sets = extract_continuous_word_sets(cleaned_text, i)\n",
    "        for word in word_sets:\n",
    "            try:\n",
    "                node_ids[word] = alias2entity[word]\n",
    "                cleaned_text = cleaned_text.replace(word, \"\")\n",
    "            except Exception as e:\n",
    "                pass\n",
    "                #print(\"KeyError: \", e)\n",
    "    return node_ids    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'isaac newton': 'Q935', 'machine learning': 'Q2539', 'invented': 'Q18119757'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_ids = (query_to_node_id(\"Who invented machine learning, was it Isaac Newton?\"))\n",
    "node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/submodules/HaluEval/data/qa_data.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "halueval_path = os.path.join(os.getcwd(), \"submodules\", \"HaluEval\", \"data\", \"qa_data.json\")\n",
    "print(halueval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with(open(halueval_path, \"r\")) as f:\n",
    "    data_lst = f.readlines()\n",
    "\n",
    "data_lst = [json.loads(data) for data in data_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEVANT_KEYS = ['knowledge', 'question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    result = {}\n",
    "    for k in RELEVANT_KEYS:\n",
    "        node_vals = query_to_node_id(data[k])\n",
    "        result.update(node_vals)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = [process_data(i) for i in data_lst[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.contrib.concurrent import process_map\n",
    "import multiprocessing as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 406/10000 [07:14<2:51:10,  1.07s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb Cell 20\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(data_lst):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     result\u001b[39m.\u001b[39mappend(process_data(data))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(end\u001b[39m-\u001b[39mstart)\n",
      "\u001b[1;32m/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb Cell 20\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m {}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m RELEVANT_KEYS:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     node_vals \u001b[39m=\u001b[39m query_to_node_id(data[k])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     result\u001b[39m.\u001b[39mupdate(node_vals)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;32m/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery_to_node_id\u001b[39m(query):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     node_ids \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     cleaned_text, named_entities \u001b[39m=\u001b[39m clean_text(query)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m ne \u001b[39min\u001b[39;00m named_entities: \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb Cell 20\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclean_text\u001b[39m(text):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Extract named entities\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m'\u001b[39m) \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     named_entities \u001b[39m=\u001b[39m nlp(text)\u001b[39m.\u001b[39ments\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# Tokenize the text\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     words \u001b[39m=\u001b[39m word_tokenize(text)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/spacy/language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[1;32m   1048\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1049\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/spacy/pipeline/tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     width \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_dim(\u001b[39m\"\u001b[39m\u001b[39mnO\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39malloc((\u001b[39m0\u001b[39m, width)) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs]\n\u001b[0;32m--> 126\u001b[0m tokvecs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(docs)\n\u001b[1;32m    127\u001b[0m \u001b[39mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/layers/with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](Xseq, is_train)\n\u001b[1;32m     41\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/layers/with_array.py:77\u001b[0m, in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     75\u001b[0m lengths \u001b[39m=\u001b[39m NUMPY_OPS\u001b[39m.\u001b[39masarray1i([\u001b[39mlen\u001b[39m(seq) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m Xs])\n\u001b[1;32m     76\u001b[0m Xf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(Xs, pad\u001b[39m=\u001b[39mpad)\n\u001b[0;32m---> 77\u001b[0m Yf, get_dXf \u001b[39m=\u001b[39m layer(Xf, is_train)\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYs: ListXd) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ListXd:\n\u001b[1;32m     80\u001b[0m     dYf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(dYs, pad\u001b[39m=\u001b[39mpad)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/layers/residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m d_output \u001b[39m+\u001b[39m dX\n\u001b[0;32m---> 41\u001b[0m Y, backprop_layer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m](X, is_train)\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(X, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m [X[i] \u001b[39m+\u001b[39m Y[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))], backprop\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "    \u001b[0;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/layers/layernorm.py:24\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model: Model[InT, InT], X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[InT, Callable]:\n\u001b[0;32m---> 24\u001b[0m     N, mu, var \u001b[39m=\u001b[39m _get_moments(model\u001b[39m.\u001b[39;49mops, X)\n\u001b[1;32m     25\u001b[0m     Xhat \u001b[39m=\u001b[39m (X \u001b[39m-\u001b[39m mu) \u001b[39m*\u001b[39m var \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m \u001b[39m2.0\u001b[39m)\n\u001b[1;32m     26\u001b[0m     Y, backprop_rescale \u001b[39m=\u001b[39m _begin_update_scale_shift(model, Xhat)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/thinc/layers/layernorm.py:75\u001b[0m, in \u001b[0;36m_get_moments\u001b[0;34m(ops, X)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_moments\u001b[39m(ops: Ops, X: Floats2d) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Floats2d, Floats2d, Floats2d]:\n\u001b[1;32m     73\u001b[0m     \u001b[39m# TODO: Do mean methods\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     mu: Floats2d \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 75\u001b[0m     var: Floats2d \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mvar(axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, keepdims\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m+\u001b[39m \u001b[39m1e-08\u001b[39m\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Floats2d, ops\u001b[39m.\u001b[39masarray_f([X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]])), mu, var\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/numpy/core/_methods.py:162\u001b[0m, in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    160\u001b[0m     div \u001b[39m=\u001b[39m rcount\u001b[39m.\u001b[39mreshape(arrmean\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arrmean, mu\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mwith\u001b[39;00m _no_nep50_warning():\n\u001b[1;32m    163\u001b[0m         arrmean \u001b[39m=\u001b[39m um\u001b[39m.\u001b[39mtrue_divide(arrmean, div, out\u001b[39m=\u001b[39marrmean,\n\u001b[1;32m    164\u001b[0m                                  casting\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m'\u001b[39m, subok\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(arrmean, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/contextlib.py:289\u001b[0m, in \u001b[0;36mcontextmanager.<locals>.helper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhelper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m _GeneratorContextManager(func, args, kwds)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/contextlib.py:104\u001b[0m, in \u001b[0;36m_GeneratorContextManagerBase.__init__\u001b[0;34m(self, func, args, kwds)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_GeneratorContextManagerBase\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Shared functionality for @contextmanager and @asynccontextmanager.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, func, args, kwds):\n\u001b[1;32m    105\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    106\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds \u001b[39m=\u001b[39m func, args, kwds\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#result = process_map(process_data, data_lst, max_workers=5)\n",
    "result = []\n",
    "for data in tqdm.tqdm(data_lst):\n",
    "    result.append(process_data(data))\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r5/bl7flfz578q7w43835k7t21w0000gn/T/ipykernel_37450/2795308879.py:4: TqdmWarning: Iterable length 10000 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  result = process_map(process_data, data_lst)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-51:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rbanerjee/opt/miniconda3/envs/MLG/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/rbanerjee/opt/miniconda3/envs/MLG/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rbanerjee/opt/miniconda3/envs/MLG/lib/python3.12/concurrent/futures/process.py\", line 246, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rbanerjee/opt/miniconda3/envs/MLG/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_data' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnProcess-52:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rbanerjee/opt/miniconda3/envs/MLG/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/rbanerjee/opt/miniconda3/envs/MLG/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rbanerjee/opt/miniconda3/envs/MLG/lib/python3.12/concurrent/futures/process.py\", line 246, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rbanerjee/opt/miniconda3/envs/MLG/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_data' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnProcess-53:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rbanerjee/opt/miniconda3/envs/MLG/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/rbanerjee/opt/miniconda3/envs/MLG/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rbanerjee/opt/miniconda3/envs/MLG/lib/python3.12/concurrent/futures/process.py\", line 246, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rbanerjee/opt/miniconda3/envs/MLG/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_data' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnProcess-54:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A child process terminated abruptly, the process pool is not usable anymore",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     result \u001b[39m=\u001b[39m process_map(process_data, data_lst)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#result = []\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#for data in tqdm.tqdm(data_lst):\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#    result.append(process_data(data))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rbanerjee/Documents/Projects/KG-LLM-Hallucination/subgraph.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/tqdm/contrib/concurrent.py:105\u001b[0m, in \u001b[0;36mprocess_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     tqdm_kwargs \u001b[39m=\u001b[39m tqdm_kwargs\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    104\u001b[0m     tqdm_kwargs[\u001b[39m\"\u001b[39m\u001b[39mlock_name\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmp_lock\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m _executor_map(ProcessPoolExecutor, fn, \u001b[39m*\u001b[39;49miterables, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtqdm_kwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/site-packages/tqdm/contrib/concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name\u001b[39m=\u001b[39mlock_name) \u001b[39mas\u001b[39;00m lk:\n\u001b[1;32m     48\u001b[0m     \u001b[39m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[39mwith\u001b[39;00m PoolExecutor(max_workers\u001b[39m=\u001b[39mmax_workers, initializer\u001b[39m=\u001b[39mtqdm_class\u001b[39m.\u001b[39mset_lock,\n\u001b[1;32m     50\u001b[0m                       initargs\u001b[39m=\u001b[39m(lk,)) \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m---> 51\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(tqdm_class(ex\u001b[39m.\u001b[39;49mmap(fn, \u001b[39m*\u001b[39;49miterables, chunksize\u001b[39m=\u001b[39;49mchunksize), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/concurrent/futures/process.py:822\u001b[0m, in \u001b[0;36mProcessPoolExecutor.map\u001b[0;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    820\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mchunksize must be >= 1.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 822\u001b[0m results \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mmap(partial(_process_chunk, fn),\n\u001b[1;32m    823\u001b[0m                       _get_chunks(\u001b[39m*\u001b[39;49miterables, chunksize\u001b[39m=\u001b[39;49mchunksize),\n\u001b[1;32m    824\u001b[0m                       timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    825\u001b[0m \u001b[39mreturn\u001b[39;00m _chain_from_iterable_of_lists(results)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/concurrent/futures/_base.py:608\u001b[0m, in \u001b[0;36mExecutor.map\u001b[0;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    606\u001b[0m     end_time \u001b[39m=\u001b[39m timeout \u001b[39m+\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 608\u001b[0m fs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubmit(fn, \u001b[39m*\u001b[39;49margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39miterables)]\n\u001b[1;32m    610\u001b[0m \u001b[39m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \u001b[39m# before the first iterator value is required.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresult_iterator\u001b[39m():\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/MLG/lib/python3.12/concurrent/futures/process.py:776\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown_lock:\n\u001b[1;32m    775\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_broken:\n\u001b[0;32m--> 776\u001b[0m         \u001b[39mraise\u001b[39;00m BrokenProcessPool(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_broken)\n\u001b[1;32m    777\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown_thread:\n\u001b[1;32m    778\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcannot schedule new futures after shutdown\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A child process terminated abruptly, the process pool is not usable anymore"
     ]
    }
   ],
   "source": [
    "from tqdm.contrib.concurrent import thread_map\n",
    "start = time.time()\n",
    "if __name__ == \"__main__\":\n",
    "    result = process_map(process_data, data_lst)\n",
    "#result = []\n",
    "#for data in tqdm.tqdm(data_lst):\n",
    "#    result.append(process_data(data))\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kghalu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
